{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install phonemizer\n!sudo apt-get install espeak-ng -y    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T11:42:14.554532Z","iopub.execute_input":"2025-08-20T11:42:14.555237Z","iopub.status.idle":"2025-08-20T11:42:30.730100Z","shell.execute_reply.started":"2025-08-20T11:42:14.555214Z","shell.execute_reply":"2025-08-20T11:42:30.729222Z"}},"outputs":[{"name":"stdout","text":"Collecting phonemizer\n  Downloading phonemizer-3.3.0-py3-none-any.whl.metadata (48 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from phonemizer) (1.5.1)\nCollecting segments (from phonemizer)\n  Downloading segments-2.3.0-py2.py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: attrs>=18.1 in /usr/local/lib/python3.11/dist-packages (from phonemizer) (25.3.0)\nCollecting dlinfo (from phonemizer)\n  Downloading dlinfo-2.0.0-py3-none-any.whl.metadata (1.1 kB)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from phonemizer) (4.14.0)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from segments->phonemizer) (2024.11.6)\nCollecting csvw>=1.5.6 (from segments->phonemizer)\n  Downloading csvw-3.5.1-py2.py3-none-any.whl.metadata (10 kB)\nCollecting isodate (from csvw>=1.5.6->segments->phonemizer)\n  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (2.9.0.post0)\nCollecting rfc3986<2 (from csvw>=1.5.6->segments->phonemizer)\n  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: uritemplate>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (4.2.0)\nRequirement already satisfied: babel in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (2.17.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (2.32.4)\nCollecting language-tags (from csvw>=1.5.6->segments->phonemizer)\n  Downloading language_tags-1.2.0-py3-none-any.whl.metadata (2.1 kB)\nCollecting rdflib (from csvw>=1.5.6->segments->phonemizer)\n  Downloading rdflib-7.1.4-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (0.4.6)\nRequirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (4.24.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.25.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->csvw>=1.5.6->segments->phonemizer) (1.17.0)\nRequirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from rdflib->csvw>=1.5.6->segments->phonemizer) (3.0.9)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer) (2025.6.15)\nDownloading phonemizer-3.3.0-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.8/103.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dlinfo-2.0.0-py3-none-any.whl (3.7 kB)\nDownloading segments-2.3.0-py2.py3-none-any.whl (15 kB)\nDownloading csvw-3.5.1-py2.py3-none-any.whl (59 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\nDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\nDownloading language_tags-1.2.0-py3-none-any.whl (213 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.4/213.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rdflib-7.1.4-py3-none-any.whl (565 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.1/565.1 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: rfc3986, language-tags, rdflib, isodate, dlinfo, csvw, segments, phonemizer\nSuccessfully installed csvw-3.5.1 dlinfo-2.0.0 isodate-0.7.2 language-tags-1.2.0 phonemizer-3.3.0 rdflib-7.1.4 rfc3986-1.5.0 segments-2.3.0\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following additional packages will be installed:\n  espeak-ng-data libespeak-ng1 libpcaudio0 libsonic0\nThe following NEW packages will be installed:\n  espeak-ng espeak-ng-data libespeak-ng1 libpcaudio0 libsonic0\n0 upgraded, 5 newly installed, 0 to remove and 38 not upgraded.\nNeed to get 4,526 kB of archives.\nAfter this operation, 11.9 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libpcaudio0 amd64 1.1-6build2 [8,956 B]\nGet:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsonic0 amd64 0.2.0-11build1 [10.3 kB]\nGet:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 espeak-ng-data amd64 1.50+dfsg-10ubuntu0.1 [3,956 kB]\nGet:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libespeak-ng1 amd64 1.50+dfsg-10ubuntu0.1 [207 kB]\nGet:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 espeak-ng amd64 1.50+dfsg-10ubuntu0.1 [343 kB]\nFetched 4,526 kB in 1s (5,135 kB/s)\ndebconf: unable to initialize frontend: Dialog\ndebconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 5.)\ndebconf: falling back to frontend: Readline\nSelecting previously unselected package libpcaudio0:amd64.\n(Reading database ... 128663 files and directories currently installed.)\nPreparing to unpack .../libpcaudio0_1.1-6build2_amd64.deb ...\nUnpacking libpcaudio0:amd64 (1.1-6build2) ...\nSelecting previously unselected package libsonic0:amd64.\nPreparing to unpack .../libsonic0_0.2.0-11build1_amd64.deb ...\nUnpacking libsonic0:amd64 (0.2.0-11build1) ...\nSelecting previously unselected package espeak-ng-data:amd64.\nPreparing to unpack .../espeak-ng-data_1.50+dfsg-10ubuntu0.1_amd64.deb ...\nUnpacking espeak-ng-data:amd64 (1.50+dfsg-10ubuntu0.1) ...\nSelecting previously unselected package libespeak-ng1:amd64.\nPreparing to unpack .../libespeak-ng1_1.50+dfsg-10ubuntu0.1_amd64.deb ...\nUnpacking libespeak-ng1:amd64 (1.50+dfsg-10ubuntu0.1) ...\nSelecting previously unselected package espeak-ng.\nPreparing to unpack .../espeak-ng_1.50+dfsg-10ubuntu0.1_amd64.deb ...\nUnpacking espeak-ng (1.50+dfsg-10ubuntu0.1) ...\nSetting up libpcaudio0:amd64 (1.1-6build2) ...\nSetting up libsonic0:amd64 (0.2.0-11build1) ...\nSetting up espeak-ng-data:amd64 (1.50+dfsg-10ubuntu0.1) ...\nSetting up libespeak-ng1:amd64 (1.50+dfsg-10ubuntu0.1) ...\nSetting up espeak-ng (1.50+dfsg-10ubuntu0.1) ...\nProcessing triggers for man-db (2.10.2-1) ...\nProcessing triggers for libc-bin (2.35-0ubuntu3.8) ...\n/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# from phonemizer import phonemize\n\n# bn_text = \"আমি ভাত খাই।\"\n# phonemes = phonemize(bn_text, language='bn', backend='espeak', strip=True)\n# print(phonemes)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T11:51:17.316639Z","iopub.execute_input":"2025-08-20T11:51:17.317058Z","iopub.status.idle":"2025-08-20T11:51:17.320918Z","shell.execute_reply.started":"2025-08-20T11:51:17.317033Z","shell.execute_reply":"2025-08-20T11:51:17.320073Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from huggingface_hub import login\nlogin()  # Will ask for your HF token\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-20T11:51:28.463050Z","iopub.execute_input":"2025-08-20T11:51:28.463324Z","iopub.status.idle":"2025-08-20T11:51:28.877952Z","shell.execute_reply.started":"2025-08-20T11:51:28.463304Z","shell.execute_reply":"2025-08-20T11:51:28.877165Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f117415264e4120800d680c12f731c8"}},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"## mozilla","metadata":{}},{"cell_type":"code","source":"# from datasets import load_dataset\n# cv_bn = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"bn\", split=\"train+validation\")\n\n# bd_keywords = [\"Dhaka\", \"Rangpur\", \"Sylhet\", \"Chittagong\", \"Barisal\", \n#                \"Khulna\", \"Mymensingh\", \"Narayanganj\", \"Gazipur\", \"Pabna\", \"Tangail\", \"Faridpur\", \"Kushtia\"]\n# is_bd = lambda acc: any(k in (acc or \"\") for k in bd_keywords)\n# filtered = [x for x in cv_bn if is_bd(x.get(\"accent\",\"\"))]\n# print(f\"Found {len(filtered)} Bangladeshi-accent clips\")\n\n\n\nfrom datasets import load_dataset\n\n# Stream from HF without loading all into RAM\ncv_bn = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"bn\", split=\"train+validation\")\n\nbd_keywords = [\"Dhaka\", \"Rangpur\", \"Sylhet\", \"Chittagong\", \"Barisal\", \n               \"Khulna\", \"Mymensingh\", \"Narayanganj\", \"Gazipur\", \"Pabna\", \"Tangail\", \"Faridpur\", \"Kushtia\"]\n\ndef is_bd(example):\n    acc = example.get(\"accent\", \"\") or \"\"\n    return any(k in acc for k in bd_keywords)\n\n# This will filter without expanding whole dataset into RAM\nfiltered = cv_bn.filter(is_bd, num_proc=4)  # num_proc speeds up\nprint(filtered)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T11:54:57.766346Z","iopub.execute_input":"2025-08-20T11:54:57.766780Z","iopub.status.idle":"2025-08-20T11:57:12.665993Z","shell.execute_reply.started":"2025-08-20T11:54:57.766756Z","shell.execute_reply":"2025-08-20T11:57:12.664887Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/12.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a8d398f99a042c69c439e1ccdd3f697"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"common_voice_17_0.py:   0%|          | 0.00/8.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0f7e234f9b647159b0353733bbe79c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"languages.py:   0%|          | 0.00/3.92k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"699f8c7092004880953c5e714ad62291"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"release_stats.py:   0%|          | 0.00/132k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b562ac6d28f48939477697616855f92"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for mozilla-foundation/common_voice_17_0 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mozilla-foundation/common_voice_17_0.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"n_shards.json:   0%|          | 0.00/17.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c44e776f4e2c4ff99adb24c8f9290774"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/train/bn_train_0.tar:   0%|          | 0.00/747M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f781836230e743f1a00e694f401a98ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/dev/bn_dev_0.tar:   0%|          | 0.00/359M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18b7b7cbfb254ef3b648737dd87db5cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/test/bn_test_0.tar:   0%|          | 0.00/367M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e2a625fe38a4d56bc5b70275b8cc2e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0/25 [00:00<?, ?files/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"543a819bd7c74b3faa624aa4299e1379"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_6.tar:   0%|          | 0.00/1.16G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bc49bc37c7e477d91fbf7f6f77c9d68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_5.tar:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3736733a749f48df9a8e14129ead6e54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_9.tar:   0%|          | 0.00/962M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6f40c6314e34506909a6ed703f80faf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_3.tar:   0%|          | 0.00/1.52G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69a3cd640aa742d1a5b6aff1cca3a0c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_1.tar:   0%|          | 0.00/1.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb7175c483f74cb19d591320163cbd6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_14.tar:   0%|          | 0.00/1.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05a584bfd67f45f49a99a6ae5deee42e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_10.tar:   0%|          | 0.00/1.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32c796ac0f3e40c0af8095f184d30782"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_0.tar:   0%|          | 0.00/1.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f387c9461ca044009de1d9dcf8981801"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_11.tar:   0%|          | 0.00/928M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3de2b106208c4c918cd8dcc74e761a3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_13.tar:   0%|          | 0.00/978M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2f9eeea6fbe46beb745a390eddb64cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_2.tar:   0%|          | 0.00/1.53G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87c5acd2c4564e349d234b1f5abb413c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_4.tar:   0%|          | 0.00/1.45G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"593930bf3d1e45bd8c7510cdc08be9a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_8.tar:   0%|          | 0.00/1.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05af72914a074cefa874f8f52c2c61bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_7.tar:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a975758c310426b8ee9b0c954847026"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_15.tar:   0%|          | 0.00/899M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e91cdd7ed3894fc4a52654e990ae6399"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_12.tar:   0%|          | 0.00/1.03G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c17a8acd3c3d470db7eede46bffbb2cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_16.tar:   0%|          | 0.00/949M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"974ab2414f0c4cd7ba934c7b29439773"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_17.tar:   0%|          | 0.00/924M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"580305da92a742a18fd1f4e84a804439"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_18.tar:   0%|          | 0.00/879M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a979954cd5a04eab94f0bbcfbc643e92"}},"metadata":{}},{"name":"stderr","text":"Cancellation requested; stopping current tasks.\n","output_type":"stream"},{"name":"stdout","text":"{\"timestamp\":\"2025-08-20T11:56:38.199670Z\",\"level\":\"ERROR\",\"fields\":{\"message\":\"Python exception updating progress:, error: PyErr { type: <class 'RuntimeError'>, value: RuntimeError('Xet Runtime Error: task 2956 was cancelled'), traceback: None }\",\"caller\":\"src/progress_update.rs:313\"},\"filename\":\"/home/runner/work/xet-core/xet-core/error_printer/src/lib.rs\",\"line_number\":28}\n{\"timestamp\":\"2025-08-20T11:56:38.203514Z\",\"level\":\"ERROR\",\"fields\":{\"message\":\"Python exception updating progress:, error: PyErr { type: <class 'RuntimeError'>, value: RuntimeError('Xet Runtime Error: task 2960 was cancelled'), traceback: None }\",\"caller\":\"src/progress_update.rs:313\"},\"filename\":\"/home/runner/work/xet-core/xet-core/error_printer/src/lib.rs\",\"line_number\":28}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_19.tar:   0%|          | 0.00/767M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfee7f477f6f410893ca7337ce613744"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_20.tar:   0%|          | 0.00/781M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91b377e84c794979964041d2dc68e4ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_21.tar:   0%|          | 0.00/766M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fc141ef90664b8e97b8210908fe2cde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_23.tar:   0%|          | 0.00/602M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0aa963821be4620b00bc3c934ff8487"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_22.tar:   0%|          | 0.00/712M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df4dbe083b8a4fa3884379a2eaa8c9a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"audio/bn/other/bn_other_24.tar:   0%|          | 0.00/1.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aee8e09dff6f4ff7a6c7e30b084b15e8"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3720837389.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Stream from HF without loading all into RAM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcv_bn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mozilla-foundation/common_voice_17_0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bn\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train+validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m bd_keywords = [\"Dhaka\", \"Rangpur\", \"Sylhet\", \"Chittagong\", \"Barisal\", \n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m     \u001b[0;31m# Download and prepare data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2084\u001b[0;31m     builder_instance.download_and_prepare(\n\u001b[0m\u001b[1;32m   2085\u001b[0m         \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2086\u001b[0m         \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                         \u001b[0mprepare_split_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_proc\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_proc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m                     self._download_and_prepare(\n\u001b[0m\u001b[1;32m    926\u001b[0m                         \u001b[0mdl_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m                         \u001b[0mverification_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverification_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[0m\n\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_download_and_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverification_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mprepare_splits_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1649\u001b[0;31m         super()._download_and_prepare(\n\u001b[0m\u001b[1;32m   1650\u001b[0m             \u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0mverification_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0msplit_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSplitDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0msplit_generators_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_split_generators_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare_split_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m         \u001b[0msplit_generators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_generators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msplit_generators_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0;31m# Checksums verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/huggingface/modules/datasets_modules/datasets/mozilla-foundation--common_voice_17_0/9d10386a731ff6e6ed4ec973a4dc204a9820e8c842fbe388bdba0dd205ed5016/common_voice_17_0.py\u001b[0m in \u001b[0;36m_split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0m_AUDIO_URL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshard_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_shards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             ]\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0marchive_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mlocal_extracted_archive_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive_paths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdl_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_streaming\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/download/download_manager.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mstack_multiprocessing_download_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             downloaded_path_or_paths = map_nested(\n\u001b[0m\u001b[1;32m    160\u001b[0m                 \u001b[0mdownload_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0murl_or_urls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mnum_proc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         mapped = [\n\u001b[0m\u001b[1;32m    505\u001b[0m             map_nested(\n\u001b[1;32m    506\u001b[0m                 \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         mapped = [\n\u001b[0;32m--> 505\u001b[0;31m             map_nested(\n\u001b[0m\u001b[1;32m    506\u001b[0m                 \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m                 \u001b[0mdata_struct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0miterable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         mapped = [\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0m_single_map_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhf_tqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0miterable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         mapped = [\n\u001b[0;32m--> 522\u001b[0;31m             \u001b[0m_single_map_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhf_tqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         ]\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     ):\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmapped_item\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmapped_item\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;31m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     ):\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmapped_item\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmapped_item\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;31m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/download/download_manager.py\u001b[0m in \u001b[0;36m_download_batched\u001b[0;34m(self, url_or_filenames, download_config)\u001b[0m\n\u001b[1;32m    204\u001b[0m             )  # enable multithreading if files are small\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             return thread_map(\n\u001b[0m\u001b[1;32m    207\u001b[0m                 \u001b[0mdownload_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0murl_or_filenames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/contrib/concurrent.py\u001b[0m in \u001b[0;36mthread_map\u001b[0;34m(fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_executor_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0miterables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtqdm_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/contrib/concurrent.py\u001b[0m in \u001b[0;36m_executor_map\u001b[0;34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m         with PoolExecutor(max_workers=max_workers, initializer=tqdm_class.set_lock,\n\u001b[1;32m     50\u001b[0m                           initargs=(lk,)) as ex:\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0miterables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    617\u001b[0m                     \u001b[0;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m                         \u001b[0;32myield\u001b[0m \u001b[0m_result_or_cancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0m_result_or_cancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":7},{"cell_type":"markdown","source":"## openslr","metadata":{}},{"cell_type":"code","source":"pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T11:53:43.501971Z","iopub.execute_input":"2025-08-20T11:53:43.502882Z","iopub.status.idle":"2025-08-20T11:53:43.506330Z","shell.execute_reply.started":"2025-08-20T11:53:43.502851Z","shell.execute_reply":"2025-08-20T11:53:43.505600Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# !apt-get install sox  # for resampling","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def phonemizer(bn_text):\n    return phonemize(bn_text, language='bn', backend='espeak', strip=True)\n\n\nimport re\n\ndef bd_text_normalize(text: str) -> str:\n    # Retroflex simplifications\n    text = text.replace(\"ড়\", \"র\")   # 'ড়' (ṛ) → 'র' (ra)\n    text = text.replace(\"ঢ়\", \"র\")   # 'ঢ়' (ṛh) → 'র' (ra)\n\n    # T-t vs ṭ-ṭh simplification (BD often flattens retroflex)\n    text = text.replace(\"ট\", \"ত\")   # 'ট' → 'ত'\n    text = text.replace(\"ঠ\", \"থ\")   # 'ঠ' → 'থ'\n    text = text.replace(\"ড\", \"দ\")   # 'ড' → 'দ'\n    text = text.replace(\"ঢ\", \"ধ\")   # 'ঢ' → 'ধ'\n\n    # Vowel normalization\n    text = text.replace(\"ঋ\", \"রি\")   # ঋ often pronounced 'ri' in BD\n    text = text.replace(\"ৠ\", \"রি\")   # long ঋ → 'ri'\n    text = re.sub(\"ঈ\", \"ই\", text)    # long 'ঈ' → 'ই' (shorter vowel in BD accent)\n    text = re.sub(\"ঊ\", \"উ\", text)    # long 'ঊ' → 'উ'\n\n    # Replace less common Sanskritic forms with modern BD forms\n    text = text.replace(\"ৎ\", \"ত\")   # final 'ৎ' → 'ত'\n    text = text.replace(\"ক্ষ\", \"খ\") # 'ক্ষ' → 'খ' (BD says 'খ')\n\n    # Nasalization simplification\n    text = text.replace(\"ঁ\", \"ং\")   # chandrabindu → anusvara (BD often drops nasalization)\n\n    # Whitespace + punctuation cleaning\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    return text\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport librosa\nimport soundfile as sf\n\n# Ensure fresh folders\nos.makedirs(\"dataset/wavs\", exist_ok=True)\n\nrecords = []\nfor idx, clip in enumerate(filtered):\n    # Generate safe filename\n    filename = f\"clip_{idx:05d}.wav\"\n    filepath = os.path.join(\"dataset/wavs\", filename)\n\n    # Load and resample audio\n    y, sr = librosa.load(clip[\"audio\"][\"path\"], sr=None)\n    y = librosa.resample(y, orig_sr=sr, target_sr=22050)\n    sf.write(filepath, y, 22050)\n\n    # Clean transcript\n    text = clip[\"sentence\"].strip()\n    if not text.endswith((\".\", \"?\", \"!\")):\n        text += \".\"\n\n    # Append correct filename + text\n    records.append([filename, bd_text_normalize(text)])\n\n# Write metadata.csv in correct format\nwith open(\"dataset/metadata.csv\", \"w\", encoding=\"utf-8\") as f:\n    for fn, txt in records:\n        f.write(f\"{txt}|{fn}\\n\")\nprint()\nprint(f\" Saved {len(records)} clips and metadata.csv\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install TTS -q  # installs coqui TTS\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T08:38:14.656729Z","iopub.execute_input":"2025-08-20T08:38:14.657441Z","iopub.status.idle":"2025-08-20T08:40:34.825322Z","shell.execute_reply.started":"2025-08-20T08:38:14.657418Z","shell.execute_reply":"2025-08-20T08:40:34.824527Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m938.0/938.0 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.2/840.2 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.1/72.1 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ndask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\ndask-expr 1.1.21 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\ncudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\nwoodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\nfeaturetools 1.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\nvisions 0.8.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\npyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.1 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nsklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.1 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nscikit-image 0.25.2 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\nnx-cugraph-cu12 25.2.0 requires networkx>=3.2, but you have networkx 2.8.8 which is incompatible.\nmizani 0.13.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\nplotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nxarray 2025.3.1 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# !pip install huggingface_hub\n\n# from huggingface_hub import snapshot_download\n# repo_id = \"bangla-speech-processing/bangla_tts_female\"\n# local_dir = snapshot_download(repo_id=repo_id)\n\n# print(\"Model files are in:\", local_dir)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T08:41:44.103523Z","iopub.execute_input":"2025-08-20T08:41:44.104360Z","iopub.status.idle":"2025-08-20T08:41:44.107837Z","shell.execute_reply.started":"2025-08-20T08:41:44.104326Z","shell.execute_reply":"2025-08-20T08:41:44.107004Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"!pip install -q huggingface_hub\n\nfrom huggingface_hub import snapshot_download\n\nrepo_id = \"bangla-speech-processing/bangla_tts_female\"\nlocal_dir = \"/kaggle/working/output/bangla_tts_female\"\n\nlocal_dir = snapshot_download(repo_id=repo_id, local_dir=local_dir)\n\nprint(\"✅ Model saved to:\", local_dir)\n!ls {local_dir}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T08:41:47.248577Z","iopub.execute_input":"2025-08-20T08:41:47.249117Z","iopub.status.idle":"2025-08-20T08:41:51.882970Z","shell.execute_reply.started":"2025-08-20T08:41:47.249093Z","shell.execute_reply":"2025-08-20T08:41:51.882178Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dd18fbc990444a591d02ef0f0980014"}},"metadata":{}},{"name":"stdout","text":"✅ Model saved to: /kaggle/working/output/bangla_tts_female\nconfig.json  pytorch_model.pth\tREADME.md\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import os, shutil\n\nold_path = os.path.join(local_dir, \"pytorch_model.pth\")\nnew_path = os.path.join(local_dir, \"best_model.pth\")\nif os.path.exists(old_path):\n    shutil.copy(old_path, new_path)\n    print(\"Renamed model_file.pth → best_model.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T06:22:04.276063Z","iopub.execute_input":"2025-08-20T06:22:04.276406Z","iopub.status.idle":"2025-08-20T06:22:05.038933Z","shell.execute_reply.started":"2025-08-20T06:22:04.276377Z","shell.execute_reply":"2025-08-20T06:22:05.038109Z"}},"outputs":[{"name":"stdout","text":"Renamed model_file.pth → best_model.pth\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T06:22:31.105817Z","iopub.execute_input":"2025-08-20T06:22:31.106553Z","iopub.status.idle":"2025-08-20T06:22:31.110131Z","shell.execute_reply.started":"2025-08-20T06:22:31.106530Z","shell.execute_reply":"2025-08-20T06:22:31.109304Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import json\nwith open(os.path.join(local_dir, \"config.json\"), \"r\", encoding=\"utf-8\") as f:\n    print(\"foudn config\")\n    base_cfg = json.load(f)\n\nbase_cfg[\"audio\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T06:24:12.344679Z","iopub.execute_input":"2025-08-20T06:24:12.345366Z","iopub.status.idle":"2025-08-20T06:24:12.352054Z","shell.execute_reply.started":"2025-08-20T06:24:12.345345Z","shell.execute_reply":"2025-08-20T06:24:12.351456Z"}},"outputs":[{"name":"stdout","text":"foudn config\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'fft_size': 1024,\n 'sample_rate': 22050,\n 'win_length': 1024,\n 'hop_length': 256,\n 'num_mels': 80,\n 'mel_fmin': 0,\n 'mel_fmax': None}"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"import json, os\n\n# Path to the downloaded pretrained model folder (what you called local_dir or local_model_dir)\nPRETRAINED_DIR = local_dir  # or whatever var you used\n\nwith open(os.path.join(PRETRAINED_DIR, \"config.json\"), \"r\", encoding=\"utf-8\") as f:\n    print(\"foudn config\")\n    base_cfg = json.load(f)\n\nchars = base_cfg[\"characters\"][\"characters\"]\npuncs = base_cfg[\"characters\"][\"punctuations\"]\n\n# Remove space from both\nchars = chars.replace(\" \", \"\")\npuncs = puncs.replace(\" \", \"\")\n\n# Decide where you want the single space (usually at start of chars)\nchars = \" \" + chars\n\n# Deduplicate while preserving order\ndef dedup_preserve_order(seq):\n    seen = set()\n    return \"\".join(ch for ch in seq if not (ch in seen or seen.add(ch)))\n\nchars = dedup_preserve_order(chars)\npuncs = dedup_preserve_order(puncs)\n\nbase_cfg[\"characters\"][\"characters\"] = chars\nbase_cfg[\"characters\"][\"punctuations\"] = puncs\n\n# Override ONLY what we need for finetuning\nbase_cfg[\"run_name\"] = \"bangla_tts_bd_accent\"\nbase_cfg[\"epochs\"] = 20\nbase_cfg[\"batch_size\"] = 12\nbase_cfg[\"eval_batch_size\"] = 6\nbase_cfg[\"learning_rate\"] = 1e-4\nbase_cfg[\"continue_path\"] = PRETRAINED_DIR  # resume from pretrained\n# Use mozilla 2-col formatter (filename|text) and your dataset path\nbase_cfg[\"datasets\"] = [{\n    \"name\": \"custom\",\n    \"formatter\": \"mozilla\",\n    \"meta_file_train\": \"/kaggle/working/dataset/metadata.csv\",\n    \"path\": \"/kaggle/working/dataset\"\n}]\n# Ensure sample_rate matches your wavs (22.05k) and audio params are sane\nbase_cfg[\"audio\"] = base_cfg.get(\"audio\", {})\nbase_cfg[\"audio\"] = {\n  \"fft_size\": 1024,\n  \"win_length\": 1024,\n  \"hop_length\": 256,\n  \"frame_shift_ms\": None,\n  \"frame_length_ms\": None,\n  \"stft_pad_mode\": \"reflect\",\n  \"sample_rate\": 22050,\n  \"resample\": False,\n  \"num_freq\": 513,\n  \"num_mels\": 513,\n  \"mel_fmin\": 0,\n  \"mel_fmax\": 8000,\n  \"feature_type\": \"linear\",  \n  \"normalize\": True,\n  \"trim_silence\": True,\n  \"trim_db\": 60\n}\n\n\n# Keep phonemes setting same as base model (don’t guess)\n# If base model used phonemes, keep it; if not, keep False\n# (Most Bangla community models are grapheme)\nuse_phonemes = base_cfg.get(\"use_phonemes\", False)\nprint(\"Trained on phonemes\",use_phonemes)\nbase_cfg[\"use_phonemes\"] = False\n# base_cfg[\"phonemizer\"] = \"espeak\"\n# base_cfg[\"phoneme_language\"] = \"bn\"\n\n\nwith open(\"config_finetune.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(base_cfg, f, ensure_ascii=False, indent=2)\n\nprint(\"✅ Wrote merged config_finetune.json using pretrained vocabulary.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T06:25:55.248281Z","iopub.execute_input":"2025-08-20T06:25:55.248847Z","iopub.status.idle":"2025-08-20T06:25:55.259141Z","shell.execute_reply.started":"2025-08-20T06:25:55.248821Z","shell.execute_reply":"2025-08-20T06:25:55.258534Z"}},"outputs":[{"name":"stdout","text":"foudn config\nTrained on phonemes False\n✅ Wrote merged config_finetune.json using pretrained vocabulary.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"unique_chars = set(base_cfg[\"characters\"][\"characters\"])\nassert len(unique_chars) == len(base_cfg[\"characters\"][\"characters\"]), \"Still have duplicates!\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T06:26:22.793468Z","iopub.execute_input":"2025-08-20T06:26:22.793736Z","iopub.status.idle":"2025-08-20T06:26:22.797688Z","shell.execute_reply.started":"2025-08-20T06:26:22.793719Z","shell.execute_reply":"2025-08-20T06:26:22.796910Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"!python3 -m TTS.bin.train_tts --config_path config_finetune.json","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!tts --text \"সরকারী বাহিনী এই সমাবেশে ত্যাংক নিয়ে আসে এবং প্রতিবাদ ছত্রভঙ্গ করার জন্য অনেক মানুষকে হত্যা করে।.\" --model_path /root/.cache/huggingface/hub/models--bangla-speech-processing--bangla_tts_female/snapshots/8e75164649d4cf977ae9a2aeb4358ee3287a68b6/best_model.pth --config_path /root/.cache/huggingface/hub/models--bangla-speech-processing--bangla_tts_female/snapshots/8e75164649d4cf977ae9a2aeb4358ee3287a68b6/config.json --out_path test_out_best.wav\n\nimport IPython.display as ipd\nipd.Audio(\"test_out_best.wav\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!tts --text \"সরকারী বাহিনী এই সমাবেশে ত্যাংক নিয়ে আসে এবং প্রতিবাদ ছত্রভঙ্গ করার জন্য অনেক মানুষকে হত্যা করে।.\" --model_path /kaggle/working/output/bangla_tts_female/pytorch_model.pth --config_path /root/.cache/huggingface/hub/models--bangla-speech-processing--bangla_tts_female/snapshots/8e75164649d4cf977ae9a2aeb4358ee3287a68b6/config.json --out_path test_out_base.wav\n\nimport IPython.display as ipd\nipd.Audio(\"test_out_base.wav\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"records[8]\n\nimport IPython.display as ipd\nipd.Audio(\"dataset/wavs/clip_00008.wav\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Mel-Cepstral Distortion (MCD)","metadata":{}},{"cell_type":"code","source":"import librosa\nimport numpy as np\n\ndef mel_cepstral_distortion(ref, gen, sr=22050):\n    # Extract MFCCs\n    ref_mfcc = librosa.feature.mfcc(y=ref, sr=sr, n_mfcc=13)\n    gen_mfcc = librosa.feature.mfcc(y=gen, sr=sr, n_mfcc=13)\n    min_len = min(ref_mfcc.shape[1], gen_mfcc.shape[1])\n    ref_mfcc, gen_mfcc = ref_mfcc[:, :min_len], gen_mfcc[:, :min_len]\n    diff = ref_mfcc - gen_mfcc\n    return np.mean(np.linalg.norm(diff, axis=0))\n\n# Example: load both audios\nref, _ = librosa.load(\"dataset/wavs/clip_00008.wav\", sr=22050)\ngen, _ = librosa.load(\"test_out_best.wav\", sr=22050)\n\nprint(\"MCD:\", mel_cepstral_distortion(ref, gen))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# PESQ (Perceptual Evaluation of Speech Quality)","metadata":{}},{"cell_type":"code","source":"# !pip install pypesq\nfrom pypesq import pesq\n\nscore = pesq(22050, ref, gen, 'wb')\nprint(\"PESQ:\", score)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## STOI (Short-Time Objective Intelligibility)","metadata":{}},{"cell_type":"code","source":"# !pip install pystoi\nimport numpy as np\n\ndef match_length(ref, gen):\n    min_len = min(len(ref), len(gen))\n    ref = ref[:min_len]\n    gen = gen[:min_len]\n    return ref, gen\n\n# Usage before STOI/PESQ\nref, gen = match_length(ref, gen)\n\nfrom pystoi import stoi\nscore = stoi(ref, gen, 22050, extended=False)\nprint(\"STOI:\", score)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Custom Loss","metadata":{}},{"cell_type":"markdown","source":"### DataLoader","metadata":{}},{"cell_type":"code","source":"from TTS.tts.datasets import load_tts_samples\nfrom TTS.tts.datasets.dataset import TTSDataset\nfrom TTS.utils.audio import AudioProcessor\nfrom TTS.config import load_config\nfrom torch.utils.data import DataLoader\nimport os\n\n\n# Paths\ndataset_path = \"/kaggle/working/dataset\"\nmetadata_path = os.path.join(dataset_path, \"metadata.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T06:26:46.517932Z","iopub.execute_input":"2025-08-20T06:26:46.518639Z","iopub.status.idle":"2025-08-20T06:26:50.675254Z","shell.execute_reply.started":"2025-08-20T06:26:46.518615Z","shell.execute_reply":"2025-08-20T06:26:50.674606Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"from TTS.tts.datasets import load_tts_samples\nfrom TTS.tts.datasets.dataset import TTSDataset\nfrom TTS.utils.audio import AudioProcessor\nfrom TTS.config import load_config\nfrom TTS.tts.utils.text.tokenizer import TTSTokenizer\nfrom torch.utils.data import DataLoader\n\n\nconfig_path = os.path.join(\"/kaggle/working/config_finetune.json\")\nconfig = load_config(config_path)\n\n# 2. Init Audio Processor\nap = AudioProcessor.init_from_config(config)\nap.num_freq = 513\nap.num_mels = 513\n\nap.feature_type = \"linear\"\n\n# 3. Init Tokenizer (⚠️ required for your version of TTSDataset)\ntokenizer, _ = TTSTokenizer.init_from_config(config)\n\n# 4. Load dataset samples\ntrain_samples, eval_samples = load_tts_samples(\n    config.datasets,\n    eval_split=True,\n    eval_split_size=0.05\n)\n\n# 5. Build the dataset (now with tokenizer ✅)\ndataset = TTSDataset(\n    outputs_per_step=config.model_args.get(\"outputs_per_step\", 1),\n    compute_linear_spec=True,\n    ap=ap,\n    samples=train_samples,\n    tokenizer=tokenizer,   # 🔑 FIXED\n    compute_f0=False,\n    compute_energy=False,\n    return_wav=True,\n    batch_group_size=0,\n    min_text_len=0,\n    max_text_len=500,\n    min_audio_len=0,\n    max_audio_len=float(\"inf\"),\n    phoneme_cache_path=None,\n    precompute_num_workers=0,\n    speaker_id_mapping=None,\n    d_vector_mapping=None,\n    language_id_mapping=None,\n    use_noise_augment=False,\n    start_by_longest=False,\n    verbose=True\n)\n\n# 6. DataLoader\ntrain_loader = DataLoader(\n    dataset,\n    batch_size=getattr(config, \"batch_size\", 8),\n    shuffle=True,\n    collate_fn=dataset.collate_fn,\n    drop_last=True\n)\n\nprint(\"✅ Ready. Train samples:\", len(train_samples), \"Eval samples:\", len(eval_samples))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T07:02:07.181742Z","iopub.execute_input":"2025-08-20T07:02:07.182353Z","iopub.status.idle":"2025-08-20T07:02:07.207488Z","shell.execute_reply.started":"2025-08-20T07:02:07.182330Z","shell.execute_reply":"2025-08-20T07:02:07.206822Z"}},"outputs":[{"name":"stdout","text":" > Setting up Audio Processor...\n | > sample_rate:22050\n | > resample:False\n | > num_mels:513\n | > log_func:np.log10\n | > min_level_db:0\n | > frame_shift_ms:None\n | > frame_length_ms:None\n | > ref_level_db:None\n | > fft_size:1024\n | > power:None\n | > preemphasis:0.0\n | > griffin_lim_iters:None\n | > signal_norm:None\n | > symmetric_norm:None\n | > mel_fmin:0\n | > mel_fmax:8000\n | > pitch_fmin:None\n | > pitch_fmax:None\n | > spec_gain:20.0\n | > stft_pad_mode:reflect\n | > max_norm:1.0\n | > clip_norm:True\n | > do_trim_silence:False\n | > trim_db:60\n | > do_sound_norm:False\n | > do_amp_to_db_linear:True\n | > do_amp_to_db_mel:True\n | > do_rms_norm:False\n | > db_level:None\n | > stats_path:None\n | > base:10\n | > hop_length:256\n | > win_length:1024\n | > Found 274 files in /kaggle/working/dataset\n\n\n> DataLoader initialization\n| > Tokenizer:\n\t| > add_blank: True\n\t| > use_eos_bos: False\n\t| > use_phonemes: False\n| > Number of instances : 261\n✅ Ready. Train samples: 261 Eval samples: 13\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/TTS/utils/audio/numpy_transforms.py:31: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n  return librosa.filters.mel(sr=sample_rate, n_fft=fft_size, n_mels=num_mels, fmin=mel_fmin, fmax=mel_fmax)\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"import torch.nn.functional as F\n\nphoneme_weight = 0.5\naccent_weight = 0.3\n\ndef accent_discriminator_loss(pred_mel):\n    # simple proxy: encourage smooth spectrograms\n    return torch.mean(torch.abs(pred_mel[:, :, 1:] - pred_mel[:, :, :-1]))\n\ndef bd_accent_loss(pred_mel, target_mel, pred_phonemes, target_phonemes):\n    mel_loss = F.mse_loss(pred_mel, target_mel)\n    phoneme_loss = F.cross_entropy(pred_phonemes, target_phonemes)\n    accent_loss = accent_discriminator_loss(pred_mel)\n    return mel_loss + phoneme_weight * phoneme_loss + accent_weight * accent_loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T07:02:14.166056Z","iopub.execute_input":"2025-08-20T07:02:14.166332Z","iopub.status.idle":"2025-08-20T07:02:14.171694Z","shell.execute_reply.started":"2025-08-20T07:02:14.166315Z","shell.execute_reply":"2025-08-20T07:02:14.170793Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"from TTS.tts.models.vits import Vits\nfrom TTS.config import load_config\nimport os\n\n# Paths\noutput_dir = \"/kaggle/working/output/bangla_tts_female/\"\nconfig_path = os.path.join(output_dir, \"config.json\")\ncheckpoint_path = os.path.join(output_dir, \"pytorch_model.pth\")  # or your latest checkpoint\n\n# Load config\nwith open(config_path, \"r\", encoding=\"utf-8\") as f:\n    config = json.load(f)\n\n\n# Paths\nconfig_path = os.path.join(\"/kaggle/working/config_finetune.json\")\ncheckpoint_path = os.path.join(local_dir, \"pytorch_model.pth\")\n\n# Load Coqpit config\nconfig = load_config(config_path)\n\n# Initialize model\nmodel = Vits.init_from_config(config)\n\n# Load checkpoint\nmodel.load_checkpoint(config, checkpoint_path, eval=False)\n\nprint(\"✅ Model loaded successfully\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T07:02:16.855536Z","iopub.execute_input":"2025-08-20T07:02:16.855824Z","iopub.status.idle":"2025-08-20T07:02:18.219264Z","shell.execute_reply.started":"2025-08-20T07:02:16.855803Z","shell.execute_reply":"2025-08-20T07:02:18.218623Z"}},"outputs":[{"name":"stdout","text":" > Setting up Audio Processor...\n | > sample_rate:22050\n | > resample:False\n | > num_mels:513\n | > log_func:np.log10\n | > min_level_db:0\n | > frame_shift_ms:None\n | > frame_length_ms:None\n | > ref_level_db:None\n | > fft_size:1024\n | > power:None\n | > preemphasis:0.0\n | > griffin_lim_iters:None\n | > signal_norm:None\n | > symmetric_norm:None\n | > mel_fmin:0\n | > mel_fmax:8000\n | > pitch_fmin:None\n | > pitch_fmax:None\n | > spec_gain:20.0\n | > stft_pad_mode:reflect\n | > max_norm:1.0\n | > clip_norm:True\n | > do_trim_silence:False\n | > trim_db:60\n | > do_sound_norm:False\n | > do_amp_to_db_linear:True\n | > do_amp_to_db_mel:True\n | > do_rms_norm:False\n | > db_level:None\n | > stats_path:None\n | > base:10\n | > hop_length:256\n | > win_length:1024\n✅ Model loaded successfully\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"import torch.optim as optim\n\n# 1. Define optimizer\noptimizer = optim.AdamW(model.parameters(), lr=1e-4, betas=(0.9, 0.98), eps=1e-9)\n\n# 2. (Optional) Scheduler\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10000, gamma=0.5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T07:16:36.883622Z","iopub.execute_input":"2025-08-20T07:16:36.883780Z","iopub.status.idle":"2025-08-20T07:16:40.785877Z","shell.execute_reply.started":"2025-08-20T07:16:36.883765Z","shell.execute_reply":"2025-08-20T07:16:40.784667Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/953521436.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 1. Define optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.98\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 2. (Optional) Scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"for epoch in range(10):\n    total_loss = 0\n    for batch in train_loader:\n        optimizer.zero_grad()\n        print(batch.keys() if isinstance(batch, dict) else type(batch), \"\\n\")\n\n        # unpack batch (adapt keys to your dataset!)\n        x = batch[\"token_id\"]            # text tokens\n        x_lengths = batch[\"token_id_lengths\"]\n        y = batch[\"mel\"]               # mel targets\n        y_lengths = batch[\"mel_lengths\"]\n        waveform = batch[\"waveform\"]   # raw waveform\n        y = y.transpose(1, 2)  # [batch, n_mels, time]\n\n        # forward pass through VITS\n        outputs = model(\n            x=x,\n            x_lengths=x_lengths,\n            y=y,\n            y_lengths=y_lengths,\n            waveform=waveform,\n        )\n\n        # VITS usually returns a dict with multiple losses\n        loss_dict = model.loss(outputs, batch)\n        loss = sum(loss_dict.values())\n\n        # backward\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch+1}: Loss = {total_loss/len(train_loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T07:02:22.419541Z","iopub.execute_input":"2025-08-20T07:02:22.419883Z","execution_failed":"2025-08-20T07:02:35.830Z"}},"outputs":[{"name":"stdout","text":"তিনি তখনকার মুসলিম সমাজে নারীর সীমিত ভূমিকার প্রতি খোভ প্রকাশ করেন; তিনি বলেন এতি রাষ্ত্রের জন্য খতিকর।.\n [!] Character ';' not found in the vocabulary. Discarding it.\ndict_keys(['token_id', 'token_id_lengths', 'speaker_names', 'linear', 'mel', 'mel_lengths', 'stop_targets', 'item_idxs', 'd_vectors', 'speaker_ids', 'attns', 'waveform', 'raw_text', 'pitch', 'energy', 'language_ids', 'audio_unique_names']) \n\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}