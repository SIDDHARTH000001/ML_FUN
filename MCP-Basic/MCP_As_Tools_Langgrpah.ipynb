{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "load_dotenv()\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=os.getenv(\"OPENAI_API_DEPLOYMENT\"),\n",
    "    azure_endpoint=os.getenv(\"OPENAI_API_ENDPOINT\"),\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fetch tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StdioServerParameters(command='uvx', args=['mcp-server-fetch'], env=None, cwd=None, encoding='utf-8', encoding_error_handler='strict')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_params = {\"command\": \"uvx\", \"args\": [\"mcp-server-fetch\"]}\n",
    "\n",
    "fetch_tools_param = StdioServerParameters(\n",
    "    command=\"uvx\",\n",
    "    args=[\"mcp-server-fetch\"],\n",
    ")\n",
    "fetch_tools_param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with stdio_client(fetch_tools_param) as (read, write):\n",
    "    async with ClientSession(read, write) as session:\n",
    "        try:\n",
    "            \n",
    "            await session.initialize()\n",
    "    \n",
    "            # Get tools\n",
    "            tools = await load_mcp_tools(session)\n",
    "            print(tools)\n",
    "            agent = create_react_agent(llm, tools)\n",
    "            response = await agent.ainvoke({\"messages\": \"can you get data from this url https://github.com/modelcontextprotocol/servers/tree/main/src/fetch\"})\n",
    "            print(response)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## puppeteer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "puppeteer_params = StdioServerParameters(\n",
    "    command=\"npx\",\n",
    "    args=[\"-y\",\"@modelcontextprotocol/server-puppeteer\" ],\n",
    ")\n",
    "\n",
    "async with stdio_client(puppeteer_params) as (read, write):\n",
    "    async with ClientSession(read, write) as session:\n",
    "        try:\n",
    "            await session.initialize()\n",
    "    \n",
    "            # Get tools\n",
    "            tools = await load_mcp_tools(session)\n",
    "            print(tools)\n",
    "            agent = create_react_agent(llm, tools)\n",
    "            response = await agent.ainvoke({\"messages\": \"can you get data from this url https://github.com/modelcontextprotocol/servers/tree/main/src/fetch and summarize it\" })\n",
    "            print(response['messages'][-1].content)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## file manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sandbox_path = os.path.abspath(os.path.join(os.getcwd(), \"sandbox\"))\n",
    "files_params = {\"command\": \"npx\", \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", sandbox_path]}\n",
    "\n",
    "file_tools = StdioServerParameters(\n",
    "    command=\"npx\",\n",
    "    args=[\"-y\",\"@modelcontextprotocol/server-filesystem\", sandbox_path ],\n",
    ")\n",
    "\n",
    "\n",
    "async with stdio_client(file_tools) as (read, write):\n",
    "    async with ClientSession(read, write) as session:\n",
    "        try:\n",
    "            await session.initialize()\n",
    "    \n",
    "            # Get tools\n",
    "            tools = await load_mcp_tools(session)\n",
    "            print(tools)\n",
    "            agent = create_react_agent(llm, tools)\n",
    "            response = await agent.ainvoke({\"messages\": \"write a detail difference between Langchain vs langraph in table format and save it in md file\" })\n",
    "            print(response['messages'][-1].content)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# playwright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StdioServerParameters(command='npx', args=['@playwright/mcp@latest'], env=None, cwd=None, encoding='utf-8', encoding_error_handler='strict')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "playwright_params = {\"command\": \"npx\", \"args\": [\"@playwright/mcp@latest\"]}\n",
    "\n",
    "playwright_params = StdioServerParameters(\n",
    "    command = \"npx\",\n",
    "    args = [\"@playwright/mcp@latest\"]\n",
    ")\n",
    "playwright_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with stdio_client(playwright_params) as (read, write):\n",
    "    async with ClientSession(read, write) as session:\n",
    "        \n",
    "        await session.initialize()\n",
    "\n",
    "        # Get tools\n",
    "        tools = await load_mcp_tools(session)\n",
    "        print(tools)\n",
    "        agent = create_react_agent(llm, tools)\n",
    "        weather_response = await agent.ainvoke({\"messages\": \"how is the weather today in bengaluru, use web search tool\"})\n",
    "        print(weather_response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiServerMCPClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now.. bring on the Agent with Tools!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "You browse the internet to accomplish your instructions.\n",
    "You are highly capable at browsing the internet independently to accomplish your task, \n",
    "including accepting all cookies and clicking 'not now' as\n",
    "appropriate to get to the content you need. If one website isn't fruitful, try another. \n",
    "Be persistent until you have solved your assignment,\n",
    "trying different options and sites as needed.\n",
    "\"\"\"\n",
    "\n",
    "sandbox_path = os.path.abspath(os.path.join(os.getcwd(), \"sandbox\"))\n",
    "\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"web_search_tool\": {\n",
    "            \"command\": \"npx\", \n",
    "            \"args\": [\"@playwright/mcp@latest\"],\n",
    "            \"transport\": \"stdio\",\n",
    "        },\n",
    "        \"browser_automation\": {\n",
    "                'command': 'npx', \n",
    "                'args': ['-y', '@modelcontextprotocol/server-puppeteer'],\n",
    "                \"transport\": \"stdio\",\n",
    "            \n",
    "        },\n",
    "        \"fetch\": {\n",
    "            \"command\": \"uvx\",\n",
    "            \"args\": [\"mcp-server-fetch\"],\n",
    "            \"transport\": \"stdio\",\n",
    "        },\n",
    "        \"filemanager\":{\n",
    "            \"command\": \"npx\",\n",
    "            \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", sandbox_path],\n",
    "            \"transport\": \"stdio\",\n",
    "        }\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = await client.get_tools()\n",
    "agent = create_react_agent(llm, tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# weather tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The weather today in Bengaluru (Sampangi Rama Nagar, Karnataka) is as follows:\\n\\n- **Current Temperature:** 23°C with light drizzle.\\n- **High/Low:** 25°C / 21°C\\n- **Wind:** 31 km/h\\n- **Humidity:** 87%\\n- **Dew Point:** 21°C\\n- **Pressure:** 1010.2 mb\\n- **UV Index:** 8 of 11\\n- **Visibility:** 6.44 km\\n- **Moon Phase:** Waning Crescent\\n\\n### Forecast:\\n- **Morning:** 22°C, Light Rain/Windy\\n- **Afternoon:** 24°C, Few Showers, Chance of Rain 33%\\n- **Evening:** 22°C, Showers, Chance of Rain 52%\\n- **Overnight:** 21°C, Few Showers, Chance of Rain 32%\\n\\n### Hourly Forecast:\\n- **Now:** 23°C, Rain, Chance of Rain 83%\\n- **12:30:** 24°C, Rain, Chance of Rain 83%\\n- **13:30:** 24°C, Rain, Chance of Rain 93%\\n- **14:30:** 24°C, Rain, Chance of Rain 90%\\n- **15:30:** 25°C, Rain, Chance of Rain 78%\\n\\nThe air quality index is good, indicating minimal impact.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_response = await agent.ainvoke({\"messages\": \"try to search and get the weather today in bengaluru\"})\n",
    "weather_response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# file manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The latest weather forecast for South India has been successfully saved in a markdown file. You can find it at the following location:\\n\\n`C:\\\\Users\\\\SIVERMA\\\\Documents\\\\Experimenting\\\\DeepSeek\\\\agents\\\\sandbox\\\\south_india_weather_forecast.md`'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filemanager_response = await agent.ainvoke({\"messages\": \"try to fetch latest forcast of weather in south india and save it into a well formated md file\"})\n",
    "filemanager_response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The article \"Using LangChain With Model Context Protocol (MCP)\" by Cobus Greyling on Medium discusses the Model Context Protocol (MCP), an open-source protocol developed by Anthropic. MCP aims to address the isolation of Large Language Model (LLM) applications from external data sources and tools. It standardizes how LLM-based applications connect to diverse systems, enabling seamless, secure, and scalable data exchange between AI agents and external resources.\\n\\nMCP uses a client-server architecture, allowing developers to build reusable, modular connectors with pre-built servers for popular platforms. Its open-source nature encourages innovation while maintaining security through features like granular permissions. MCP aims to transform AI agents into context-aware, interoperable systems integrated into digital environments.\\n\\nThe article also provides step-by-step instructions for connecting MCP servers to LangGraph agents and using MCP tools, including setting up a virtual environment, installing necessary packages, and running server and client code.\\n\\nIf you need more specific details or the continuation of the article, please let me know!'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_response = await agent.ainvoke({\"messages\": \"can you get data from this url https://cobusgreyling.medium.com/using-langchain-with-model-context-protocol-mcp-e89b87ee3c4c\"})\n",
    "fetch_response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have created a well-documented markdown file on how to use MCP servers with LangChain. You can find the file at the following path:\\n\\n[C:\\\\Users\\\\SIVERMA\\\\Documents\\\\Experimenting\\\\DeepSeek\\\\how_to_use_mcp_servers.md](sandbox/C:\\\\Users\\\\SIVERMA\\\\Documents\\\\Experimenting\\\\DeepSeek\\\\how_to_use_mcp_servers.md)\\n\\nThe document includes an introduction to the Model Context Protocol (MCP), its key features, and a step-by-step guide on setting up MCP with LangChain. If you have any questions or need further assistance, feel free to ask!'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_response = await agent.ainvoke({\"messages\": \"summarize the content from this https://cobusgreyling.medium.com/using-langchain-with-model-context-protocol-mcp-e89b87ee3c4c and put this in a well documented md file how to use MCP servers\"})\n",
    "fetch_response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='browser_close', description='Close the page', args_schema={'type': 'object', 'properties': {}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}, metadata={'title': 'Close browser', 'readOnlyHint': True, 'destructiveHint': False, 'idempotentHint': None, 'openWorldHint': True}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x0000018D6A29CE00>),\n",
       " StructuredTool(name='browser_resize', description='Resize the browser window', args_schema={'type': 'object', 'properties': {'width': {'type': 'number', 'description': 'Width of the browser window'}, 'height': {'type': 'number', 'description': 'Height of the browser window'}}, 'required': ['width', 'height'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}, metadata={'title': 'Resize browser window', 'readOnlyHint': True, 'destructiveHint': False, 'idempotentHint': None, 'openWorldHint': True}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x0000018D6A364400>),\n",
       " StructuredTool(name='browser_console_messages', description='Returns all console messages', args_schema={'type': 'object', 'properties': {}, 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}, metadata={'title': 'Get console messages', 'readOnlyHint': True, 'destructiveHint': False, 'idempotentHint': None, 'openWorldHint': True}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x0000018D6A3647C0>)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "tools = await client.get_tools()\n",
    "tools[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Push Notification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "import requests\n",
    "\n",
    "\n",
    "pushover_token = \"a1axxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "pushover_user = \"ga8kxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "pushover_url = \"https://api.pushover.net/1/messages.json\"\n",
    "\n",
    "def push(text: str, sound_type: str = \"magic\"):\n",
    "    \"\"\"Send a push notification to the user\"\"\"\n",
    "    res = requests.post(\n",
    "        pushover_url, \n",
    "        data = {\"token\": pushover_token, \"user\": pushover_user, \"message\": text, \"sound\": sound_type})\n",
    "    print(res)\n",
    "\n",
    "tool_push = Tool(\n",
    "        name=\"send_push_notification\",\n",
    "        func=push,\n",
    "        description=\"useful for when you want to send a push notification\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = tools + [tool_push]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def call_model(state: MessagesState):\n",
    "    response = llm.bind_tools(tools).invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(call_model)\n",
    "builder.add_node(ToolNode(tools))\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_conditional_edges(\n",
    "    \"call_model\",\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"call_model\")\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(graph.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_response = await graph.ainvoke({\"messages\": \"latest news as of today and how they will manipulate the sotck market in upcomin days use web search tool? put the response in well formated md file and save it\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The latest news and their potential impact on the stock market have been compiled and saved in a markdown file. You can find the file at:\\n\\n`C:\\\\Users\\\\SIVERMA\\\\Documents\\\\Experimenting\\\\DeepSeek\\\\agents\\\\sandbox\\\\latest_news_stock_market.md`'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with push notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "push_response = await graph.ainvoke({\"messages\": \"get the weather forcast with online search for tomorrow in bengaluru and notify user for accordingly be ready\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I've sent you a push notification with the weather alert for Bengaluru tomorrow. Stay prepared for thundery showers and a fresh breeze!\""
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "push_response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agentic_beast",
   "language": "python",
   "name": "my-env-name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
